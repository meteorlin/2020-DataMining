{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import lightgbm as lgb\n",
    "from collections import Counter\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feats(txt_path, mode='is_train'):\n",
    "    df_ = pd.read_csv(txt_path, sep=';', header=None)\n",
    "    df_['link'] = df_[0].apply(lambda x: x.split(' ')[0])\n",
    "    if mode == 'is_train':\n",
    "        df_['label'] = df_[0].apply(lambda x: int(x.split(' ')[1]))\n",
    "        df_['label'] = df_['label'].apply(lambda x: 3 if x > 3 else x)\n",
    "        df_['label'] -= 1\n",
    "        df_['current_slice_id'] = df_[0].apply(lambda x: int(x.split(' ')[2]))\n",
    "        df_['future_slice_id'] = df_[0].apply(lambda x: int(x.split(' ')[3]))\n",
    "    else:\n",
    "        df_['label'] = -1\n",
    "        df_['current_slice_id'] = df_[0].apply(lambda x: int(x.split(' ')[2]))\n",
    "        df_['future_slice_id'] = df_[0].apply(lambda x: int(x.split(' ')[3]))\n",
    "\n",
    "    df_.drop([0], axis=1, inplace=True)\n",
    "    df_['time_diff'] = df_['future_slice_id'] - df_['current_slice_id']\n",
    "\n",
    "    for ii in range(0, 5):\n",
    "        df_['curr_state'] = df_[1].apply(lambda x: x.split(' ')[ii].split(':')[-1])\n",
    "        if ii == 4:\n",
    "            flg = 'curr'\n",
    "        else:\n",
    "            flg = f'rec_{(4 - ii) * 2}'\n",
    "        df_[f'{flg}_speed'] = df_['curr_state'].apply(lambda x: x.split(',')[0])\n",
    "        df_[f'{flg}_eta'] = df_['curr_state'].apply(lambda x: x.split(',')[1])\n",
    "        df_[f'{flg}_cnt'] = df_['curr_state'].apply(lambda x: x.split(',')[3])\n",
    "        df_[f'{flg}_state'] = df_['curr_state'].apply(lambda x: x.split(',')[2])\n",
    "    df_.drop([1], axis=1, inplace=True)\n",
    "    print('recent_gen complete')\n",
    "\n",
    "    for ii in range(2, 6):\n",
    "        df_['his_info'] = df_[ii].apply(lambda x: [j.split(':')[-1] for j in x.split(' ')])\n",
    "        flg = f'his_{(6 - ii) * 7}'\n",
    "        df_['his_speed'] = df_['his_info'].apply(lambda x: np.array([j.split(',')[0] for j in x], dtype='float16'))\n",
    "        df_[f'{flg}_speed_min'] = df_['his_speed'].apply(lambda x: x.min())\n",
    "        df_[f'{flg}_speed_max'] = df_['his_speed'].apply(lambda x: x.max())\n",
    "        df_[f'{flg}_speed_mean'] = df_['his_speed'].apply(lambda x: x.mean())\n",
    "        df_[f'{flg}_speed_std'] = df_['his_speed'].apply(lambda x: x.std())\n",
    "\n",
    "        df_['his_eta'] = df_['his_info'].apply(lambda x: np.array([j.split(',')[1] for j in x], dtype='float16'))\n",
    "        df_[f'{flg}_eta_min'] = df_['his_eta'].apply(lambda x: x.min())\n",
    "        df_[f'{flg}_eta_max'] = df_['his_eta'].apply(lambda x: x.max())\n",
    "        df_[f'{flg}_eta_mean'] = df_['his_eta'].apply(lambda x: x.mean())\n",
    "        df_[f'{flg}_eta_std'] = df_['his_eta'].apply(lambda x: x.std())\n",
    "\n",
    "        df_['his_cnt'] = df_['his_info'].apply(lambda x: np.array([j.split(',')[3] for j in x], dtype='int16'))\n",
    "        df_[f'{flg}_cnt_min'] = df_['his_cnt'].apply(lambda x: x.min())\n",
    "        df_[f'{flg}_cnt_max'] = df_['his_cnt'].apply(lambda x: x.max())\n",
    "        df_[f'{flg}_cnt_mean'] = df_['his_cnt'].apply(lambda x: x.mean())\n",
    "        df_[f'{flg}_cnt_std'] = df_['his_cnt'].apply(lambda x: x.std())\n",
    "\n",
    "        df_['his_state'] = df_['his_info'].apply(lambda x: [int(j.split(',')[2]) for j in x])\n",
    "        df_[f'{flg}_state'] = df_['his_state'].apply(lambda x: Counter(x).most_common()[0][0])\n",
    "        df_.drop([ii, 'his_info', 'his_speed', 'his_eta', 'his_cnt', 'his_state'], axis=1, inplace=True)\n",
    "    print('history_gen complete')\n",
    "    if mode == 'is_train':\n",
    "        save_path = f\"{path}feature/{mode}_{txt_path.split('/')[-1][:-4]}.csv\"\n",
    "        df_.to_csv(save_path, index=False)\n",
    "        return save_path\n",
    "    else:\n",
    "        save_path = f\"{path}feature/is_test.csv\"\n",
    "        df_.to_csv(save_path, index=False)\n",
    "        return save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_eval(preds, valid_df):\n",
    "    labels = valid_df.get_label()\n",
    "    preds = np.argmax(preds.reshape(3, -1), axis=0)\n",
    "    scores = f1_score(y_true=labels, y_pred=preds, average=None)\n",
    "    scores = scores[0]*0.2+scores[1]*0.2+scores[2]*0.6\n",
    "    return 'f1_score', scores, True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_train(train_: pd.DataFrame, test_: pd.DataFrame, use_train_feats: list, id_col: str, label: str,\n",
    "              n_splits: int, split_rs: int, is_shuffle=True, use_cart=False, cate_cols=None, ground_truth_test=False) -> pd.DataFrame:\n",
    "    if not cate_cols:\n",
    "        cate_cols = []\n",
    "    print('data shape:\\ntrain--{}\\ntest--{}'.format(train_.shape, test_.shape))\n",
    "    print('Use {} features ...'.format(len(use_train_feats)))\n",
    "    print('Use lightgbm to train ...')\n",
    "    n_class = train_[label].nunique()\n",
    "    train_[f'{label}_pred'] = 0\n",
    "    if ground_truth_test:\n",
    "        test_[f'{label}_pred'] = 0\n",
    "    test_pred = np.zeros((test_.shape[0], n_class))\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = use_train_feats\n",
    "\n",
    "    folds = KFold(n_splits=n_splits, shuffle=is_shuffle, random_state=split_rs)\n",
    "    train_user_id = train_[id_col].unique()\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': 0.05,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': 'None',\n",
    "        'num_leaves': 31,\n",
    "        'num_class': n_class,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'seed': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction_seed': 7,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'nthread': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_user_id), start=1):\n",
    "        print('the {} training start ...'.format(n_fold))\n",
    "        train_x, train_y = train_.loc[train_[id_col].isin(train_user_id[train_idx]), use_train_feats], train_.loc[\n",
    "            train_[id_col].isin(train_user_id[train_idx]), label]\n",
    "        valid_x, valid_y = train_.loc[train_[id_col].isin(train_user_id[valid_idx]), use_train_feats], train_.loc[\n",
    "            train_[id_col].isin(train_user_id[valid_idx]), label]\n",
    "        print(f'for train user:{len(train_idx)}\\nfor valid user:{len(valid_idx)}')\n",
    "\n",
    "        if use_cart:\n",
    "            dtrain = lgb.Dataset(train_x, label=train_y, categorical_feature=cate_cols)\n",
    "            dvalid = lgb.Dataset(valid_x, label=valid_y, categorical_feature=cate_cols)\n",
    "        else:\n",
    "            dtrain = lgb.Dataset(train_x, label=train_y)\n",
    "            dvalid = lgb.Dataset(valid_x, label=valid_y)\n",
    "\n",
    "        clf = lgb.train(\n",
    "            params=params,\n",
    "            train_set=dtrain,\n",
    "            num_boost_round=5000,\n",
    "            valid_sets=[dvalid],\n",
    "            valid_names=['valid'],\n",
    "            early_stopping_rounds=100,\n",
    "            verbose_eval=100,\n",
    "            feval=f1_score_eval\n",
    "        )\n",
    "        fold_importance_df[f'fold_{n_fold}_imp'] = clf.feature_importance(importance_type='gain')\n",
    "        train_.loc[train_[id_col].isin(train_user_id[valid_idx]), f'{label}_pred'] = np.argmax(\n",
    "            clf.predict(valid_x, num_iteration=clf.best_iteration), axis=1)\n",
    "        test_pred += clf.predict(test_[use_train_feats], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "    report = f1_score(train_[label], train_[f'{label}_pred'], average=None)\n",
    "    print(classification_report(train_[label], train_[f'{label}_pred'], digits=4))\n",
    "    print('Train score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)\n",
    "    test_[f'{label}_pred'] = np.argmax(test_pred, axis=1)\n",
    "\n",
    "    if ground_truth_test:\n",
    "        report = f1_score(test_[label], test_[f'{label}_pred'], average=None)\n",
    "        print(classification_report(test_[label], test_[f'{label}_pred'], digits=4))\n",
    "        print('Test score: ', report[0] * 0.2 + report[1] * 0.2 + report[2] * 0.6)\n",
    "    else:\n",
    "        test_[label] = np.argmax(test_pred, axis=1) + 1\n",
    "    five_folds = [f'fold_{f}_imp' for f in range(1, n_splits + 1)]\n",
    "    fold_importance_df['avg_imp'] = fold_importance_df[five_folds].mean(axis=1)\n",
    "    fold_importance_df.sort_values(by='avg_imp', ascending=False, inplace=True)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    print(fold_importance_df[['Feature', 'avg_imp']].head(20))\n",
    "    return test_[[id_col, 'current_slice_id', 'future_slice_id', label]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    path = './'\n",
    "    train_path = {'./traffic/20190701.txt':61976, './traffic/20190702.txt':63637, \n",
    "                  './traffic/20190703.txt':63751, './traffic/20190704.txt':71428, \n",
    "                 './traffic/20190705.txt':74420, './traffic/20190706.txt':202425, \n",
    "                 './traffic/20190707.txt':66959, './traffic/20190708.txt':64188}\n",
    "    test_path = './traffic/20190709.txt'\n",
    "    # test_path = './test.txt'\n",
    "    ground_truth_test_ = False  # whether test file is train file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent_gen complete\n",
      "history_gen complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./feature/is_test.csv'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # gen_feats(train_path, mode='is_train')\n",
    "    gen_feats(test_path, mode='is_test' if not ground_truth_test_ else 'is_train')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    attr = pd.read_csv('attr.txt', sep='\\t',\n",
    "                       names=['link', 'length', 'direction', 'path_class', 'speed_class', 'LaneNum', 'speed_limit',\n",
    "                              'level', 'width'], header=None)\n",
    "    attr.drop(['level'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 504891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    train = pd.DataFrame()\n",
    "    for trainp, n_row in train_path.items():\n",
    "        train_tmp = pd.read_csv(f\"./feature/is_train_{trainp.split('/')[-1][:-4]}.csv\")\n",
    "        train_tmp['id'] = range(0, train_tmp.shape[0])\n",
    "        train_row = pd.read_csv(f\"{path}adversarial_validation/adversarial_validation_{trainp.split('/')[-1][:-4]}.csv\", nrows=n_row)\n",
    "        train_tmp = train_tmp.merge(train_row, on='id', how='right')\n",
    "        train_tmp.drop(['id', 'preds'], axis=1, inplace=True)\n",
    "        train = pd.concat([train, train_tmp], axis=0, ignore_index=True)\n",
    "    del train_tmp\n",
    "\n",
    "    test = pd.read_csv(\"./feature/is_test.csv\" if not ground_truth_test_ else f\"./feature/is_train_{test_path.split('/')[-1][:-4]}.csv\")\n",
    "    train = train.merge(attr, on='link', how='left')\n",
    "    test = test.merge(attr, on='link', how='left')\n",
    "    print(f'test size: {test.shape[0]}')\n",
    "    del attr, train_row\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    use_cols = [i for i in train.columns if i not in ['link', 'label',\n",
    "                                                      'label_pred', 'curr_cnt', 'rec_6_cnt', 'rec_2_cnt',\n",
    "                                                      'rec_8_cnt', 'rec_4_cnt', 'rec_4_eta', 'rec_2_eta', 'width',\n",
    "                                                      'rec_6_eta', 'speed_class']]\n",
    "\n",
    "    sub = lgb_train(train, test, use_cols, 'link', 'label', 5, 2020, ground_truth_test=ground_truth_test_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if not ground_truth_test_:\n",
    "        sub.to_csv(f'test_result_{len(train_path)}.csv', index=False, encoding='utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch1.5",
   "language": "python",
   "name": "py37_pytorch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
